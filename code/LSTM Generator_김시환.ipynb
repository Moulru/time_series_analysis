{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","mount_file_id":"1SCya2PmqrbHEyqezxhFNVnqSDHwU3gnX","authorship_tag":"ABX9TyPAnFuMy7cMm9v2JGBX40GY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# !pip install tensorflow==2.11.0\n","# !pip install tqdm"],"metadata":{"id":"3NoPPXrPovT_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"EgmO6vQr2zuF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import os, glob\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras import layers, models"],"metadata":{"id":"rLnpR2J92rm0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 이미지 불러오기"],"metadata":{"id":"fVIoF-lGrLPh"}},{"cell_type":"code","source":["def load_images_from_folder(folder, target_size=(256, 256)):\n","    paths = sorted(glob.glob(os.path.join(folder, '*.png')))\n","    images = []\n","    for path in paths:\n","        img = Image.open(path).convert('L').resize(target_size)  # 이미지를 그레이스케일로 변환하고 크기 조정\n","        img_array = np.array(img) / 255.0 # 0-1 범위로 정규화\n","        images.append(img_array[..., np.newaxis])  # (128,128,1) # 채널 차원 추가 (128,128,1)\n","    return np.array(images)\n","\n","image_folder = \"drive/MyDrive/Colab Notebooks/Project2/Model/img256\"\n","images = load_images_from_folder(image_folder)\n","print(\"Loaded image shape:\", images.shape)  # 이미지 shape 출력 : (n, 128, 128, 1)"],"metadata":{"id":"QjWfqNUDovgz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Autoencoder 정의 및 학습"],"metadata":{"id":"yi9iaifLrOQr"}},{"cell_type":"code","source":["def build_autoencoder():\n","    # 인코더\n","    encoder_input = layers.Input(shape=(256, 256, 1))\n","    x = layers.Conv2D(32, 3, strides=2, activation='relu', padding='same')(encoder_input)\n","    x = layers.Conv2D(64, 3, strides=2, activation='relu', padding='same')(x)\n","    x = layers.Flatten()(x)\n","    encoded = layers.Dense(100)(x)\n","\n","    # 디코더\n","    x = layers.Dense(64 * 64 * 64, activation='relu')(encoded)\n","    x = layers.Reshape((64, 64, 64))(x)\n","    x = layers.Conv2DTranspose(64, 3, strides=2, activation='relu', padding='same')(x)\n","    x = layers.Conv2DTranspose(32, 3, strides=2, activation='relu', padding='same')(x)\n","    decoder_output = layers.Conv2DTranspose(1, 3, activation='sigmoid', padding='same')(x)\n","\n","    autoencoder = models.Model(encoder_input, decoder_output)\n","    encoder = models.Model(encoder_input, encoded)\n","    return autoencoder, encoder\n","\n","autoencoder, encoder = build_autoencoder() # 모델 생\n","autoencoder.compile(optimizer='adam', loss='mse')\n","autoencoder.summary()"],"metadata":{"id":"xRvoTXMcozlY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습\n","autoencoder.fit(images, images, epochs=20, batch_size=32)"],"metadata":{"id":"clblDiqPPHjq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 이미지 → 벡터 인코딩 및 시계열 구성"],"metadata":{"id":"wMTpCzlOrQ8b"}},{"cell_type":"code","source":["latents = encoder.predict(images) # 인코더를 통해 잠재 변수(latent) 추출\n","\n","# 잠재 변수들을 시계열 데이터로 변환\n","def create_sequences(data, seq_len=12):\n","    sequences = []\n","    for i in range(len(data) - seq_len):\n","        sequences.append(data[i:i+seq_len])\n","    return np.array(sequences)\n","\n","seq_data = create_sequences(latents, seq_len=12)\n","print(\"TimeGAN input shape:\", seq_data.shape)"],"metadata":{"id":"bKndftm9o02a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LSTM Generator"],"metadata":{"id":"ZrN2TfkirVTC"}},{"cell_type":"code","source":["# LSTM Generator 모델\n","def build_lstm_generator(seq_len=12, latent_dim=100):\n","    model = models.Sequential([\n","        layers.Input(shape=(seq_len, latent_dim)),\n","        layers.LSTM(128, return_sequences=True),\n","        layers.LSTM(100, return_sequences=False),\n","        layers.Dense(latent_dim)\n","    ])\n","    model.compile(optimizer='adam', loss='mse')\n","    return model\n","\n","lstm_gen = build_lstm_generator()\n","X = seq_data[:, :-1, :] # 입력 시퀀스\n","y = seq_data[:, -1, :] # 타겟 값\n","lstm_gen.fit(X, y, epochs=100, batch_size=1)"],"metadata":{"id":"ftc8iU5zo2X1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 생성된 벡터 → 이미지 디코딩 및 시각화"],"metadata":{"id":"3kT61a2Iryi6"}},{"cell_type":"code","source":["pred_latent = lstm_gen.predict(X) # 예측된 잠재 변수\n","\n","# 디코더 모 정의\n","decoder_input = layers.Input(shape=(100,))\n","x = layers.Dense(64 * 64 * 64, activation='relu')(decoder_input)\n","x = layers.Reshape((64, 64, 64))(x)\n","x = layers.Conv2DTranspose(64, 3, strides=2, activation='relu', padding='same')(x)\n","x = layers.Conv2DTranspose(32, 3, strides=2, activation='relu', padding='same')(x)\n","decoder_output = layers.Conv2DTranspose(1, 3, activation='sigmoid', padding='same')(x)\n","decoder = models.Model(decoder_input, decoder_output)\n","\n","# 오토인코더의 가중치를 디코더에 전달\n","for i in range(len(decoder.layers)):\n","    try:\n","        decoder.layers[i].set_weights(autoencoder.layers[-(len(decoder.layers)-i)].get_weights())\n","    except:\n","        pass\n","\n","\n","reconstructed_imgs = decoder.predict(pred_latent)\n","print(reconstructed_imgs.shape)"],"metadata":{"id":"HRPv9hNio3rF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 이미지 복원 비교"],"metadata":{"id":"z-HZm0KDr0tB"}},{"cell_type":"code","source":["# MSE (Mean Squared Error) 계산\n","from sklearn.metrics import mean_squared_error\n","\n","index = 0\n","real_image = images[index+12].squeeze()  # 실제 이미지\n","predicted_image = reconstructed_imgs[index].squeeze()  # 예측 이미지\n","\n","# MSE 계산\n","mse = mean_squared_error(real_image.flatten(), predicted_image.flatten())\n","\n","max_pixel_value = 1.0\n","difference_percentage = mse / (max_pixel_value ** 2) * 100\n","\n","plt.figure(figsize=(8, 4))\n","plt.subplot(1, 2, 1)\n","plt.imshow(images[index+12].squeeze(), cmap='gray')  # 실제\n","plt.title('Real Next Image')\n","\n","plt.subplot(1, 2, 2)\n","plt.imshow(reconstructed_imgs[index].squeeze(), cmap='gray')  # 예측\n","plt.title(f'Predicted Image \\n Difference Percentage:{difference_percentage:.2f}%')\n","plt.show()\n"],"metadata":{"id":"jywKlpGXCOfe"},"execution_count":null,"outputs":[]}]}