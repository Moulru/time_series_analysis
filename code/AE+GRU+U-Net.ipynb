{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNJ5YM2gyEoYNLKsrMls7Hh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lxejASlo35CC"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# 이미지 불러오기\n","import os, glob\n","import numpy as np\n","from PIL import Image\n","\n","def load_images_from_folder(folder, target_size=(256, 256)):\n","    paths = sorted(glob.glob(os.path.join(folder, '*.png')))\n","    images = []\n","    for path in paths:\n","        img = Image.open(path).convert('L').resize(target_size)\n","        img_array = np.array(img) / 255.0\n","        images.append(img_array[..., np.newaxis])  # (256,256,1)\n","    return np.array(images)\n","\n","image_folder = \"drive/MyDrive/Colab Notebooks/Project2/Model/img256\"\n","images = load_images_from_folder(image_folder)\n","print(\"Loaded image shape:\", images.shape)  # (N, 256, 256, 1)"],"metadata":{"id":"yfuomWN04Fpo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 시퀀스 데이터 생성 (12장 입력 → 13번째 예측)\n","seq_len = 12\n","X, y = [], []\n","for i in range(len(images) - seq_len):\n","    X.append(images[i:i+seq_len])  # (12, 256, 256, 1)\n","    y.append(images[i+seq_len])    # (256, 256, 1)\n","X = np.array(X)\n","y = np.array(y)\n","print(\"X shape:\", X.shape, \"y shape:\", y.shape)"],"metadata":{"id":"7XkJgO1K4GjQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Autoencoder 인코더 정의\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","\n","encoding_dim = 256\n","\n","def build_encoder(input_shape=(256, 256, 1), latent_dim=256):\n","    inputs = layers.Input(shape=input_shape)\n","    x = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n","    x = layers.MaxPooling2D(2)(x)  # 128x128\n","    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n","    x = layers.MaxPooling2D(2)(x)  # 64x64\n","    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n","    x = layers.MaxPooling2D(2)(x)  # 32x32\n","    x = layers.Flatten()(x)\n","    latent = layers.Dense(latent_dim)(x)\n","    return models.Model(inputs, latent, name='Encoder')\n","\n","\n","encoder = build_encoder()\n","print(encoder.summary())"],"metadata":{"id":"5Suzck5R4KRT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# AE 구조 학습 후 예측된 latent가 아닌, 진짜 latent로 복원 가능한지 테스트\n","latent = encoder.predict(images[0:1])\n","reconstructed = decoder.predict(latent)\n","\n","plt.imshow(reconstructed[0].squeeze(), cmap='gray')"],"metadata":{"id":"f5Z4qQYQ5kmN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras import layers, models\n","\n","def build_decoder(latent_dim=256):\n","    inputs = layers.Input(shape=(latent_dim,))\n","    x = layers.Dense(32*32*128, activation='relu')(inputs)\n","    x = layers.Reshape((32, 32, 128))(x)\n","    x = layers.Conv2DTranspose(128, 3, strides=2, padding='same', activation='relu')(x)  # 64x64\n","    x = layers.Conv2DTranspose(64, 3, strides=2, padding='same', activation='relu')(x)   # 128x128\n","    x = layers.Conv2DTranspose(32, 3, strides=2, padding='same', activation='relu')(x)   # 256x256\n","    outputs = layers.Conv2D(1, 3, activation='sigmoid', padding='same')(x)\n","    return models.Model(inputs, outputs, name='Decoder')\n","\n"],"metadata":{"id":"ENA84xnE4Kkd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 연결\n","encoder = build_encoder()\n","decoder = build_decoder()\n","ae_input = layers.Input(shape=(256, 256, 1))\n","latent = encoder(ae_input)\n","recon = decoder(latent)\n","autoencoder = models.Model(ae_input, recon)\n","autoencoder.compile(optimizer='adam', loss='mse')\n","\n","# 학습\n","history = autoencoder.fit(images, images, epochs=50, batch_size=32, validation_split=0.1)\n"],"metadata":{"id":"ro9Gb1_z6JgE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.plot(history.history['loss'], label='train_loss')\n","plt.plot(history.history['val_loss'], label='val_loss')\n","plt.title('Autoencoder Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"gZK8OYSr9Uhq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_img = images[0:1]\n","recon_img = autoencoder.predict(test_img)\n","\n","plt.subplot(1,2,1)\n","plt.title(\"Original\")\n","plt.imshow(test_img[0].squeeze(), cmap='gray')\n","\n","plt.subplot(1,2,2)\n","plt.title(\"Reconstructed\")\n","plt.imshow(recon_img[0].squeeze(), cmap='gray')\n","plt.show()\n"],"metadata":{"id":"awGvo-6c6NXq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GRU 시계열 예측기 정의\n","def build_gru_predictor(seq_len, latent_dim):\n","    model = models.Sequential([\n","        layers.GRU(128, input_shape=(seq_len, latent_dim)),\n","        layers.Dense(latent_dim)\n","    ])\n","    return model\n","\n","predictor = build_gru_predictor(seq_len, encoding_dim)\n","predictor.compile(optimizer='adam', loss='mse')\n","print(predictor.summary())"],"metadata":{"id":"z3lfFuIb4M_3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이미지 ➝ latent 변환\n","latent_seqs = []\n","latent_targets = []\n","for i in range(len(X)):\n","    latent_seq = [encoder(img[np.newaxis, ...])[0].numpy() for img in X[i]]\n","    latent_seqs.append(latent_seq)\n","    latent_target = encoder(y[i][np.newaxis, ...])[0].numpy()\n","    latent_targets.append(latent_target)\n","\n","latent_seqs = np.array(latent_seqs)\n","latent_targets = np.array(latent_targets)\n","\n","print(\"Latent sequence shape:\", latent_seqs.shape)\n","print(\"Latent target shape:\", latent_targets.shape)"],"metadata":{"id":"N2bmBX9-4L4j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","# (1) latent_seqs: (num_samples, 12, latent_dim)\n","# (2) latent_targets: (num_samples, latent_dim)\n","\n","# reshape for scaling\n","latent_seqs_reshaped = latent_seqs.reshape(-1, latent_seqs.shape[-1])\n","scaler = StandardScaler()\n","latent_seqs_scaled = scaler.fit_transform(latent_seqs_reshaped).reshape(latent_seqs.shape)\n","\n","latent_targets_scaled = scaler.transform(latent_targets)\n"],"metadata":{"id":"hbx18rB1_y7z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import GRU, Dropout, Dense\n","\n","latent_dim = latent_seqs.shape[-1]\n","\n","predictor = Sequential([\n","    GRU(128, input_shape=(12, latent_dim)),\n","    Dropout(0.2),\n","    Dense(latent_dim)\n","])\n","predictor.compile(optimizer='adam', loss='mse')\n","predictor.summary()"],"metadata":{"id":"E5CItTBxABxY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 8. GRU 훈련\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","history_gru = predictor.fit(latent_seqs_scaled, latent_targets_scaled,\n","                            epochs=100,\n","                            batch_size=32,\n","                            validation_split=0.1,\n","                            callbacks=[early_stop])"],"metadata":{"id":"u1RYW_1X4Ngl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(history_gru.history['loss'], label='train_loss')\n","plt.plot(history_gru.history['val_loss'], label='val_loss')\n","plt.title('GRU Predictor Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"Y4XYdRHN9Z5m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === 예측 및 복원 ===\n","\n","idx = 0  # 테스트할 시퀀스 인덱스\n","\n","# predicted_latent = predictor.predict(latent_seqs_scaled[idx:idx+1])\n","# predicted_image = decoder.predict(predicted_latent)\n","\n","# GRU 예측 (정규화된 latent vector)\n","predicted_latent_scaled = predictor.predict(latent_seqs_scaled[idx:idx+1])\n","\n","# 역정규화\n","predicted_latent = scaler.inverse_transform(predicted_latent_scaled)\n","\n","# 디코더로 이미지 복원\n","predicted_image = decoder.predict(predicted_latent)\n","\n","# 시각화\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(18,6))\n","plt.subplot(1,3,1)\n","plt.title(\"Ground Truth\")\n","plt.imshow(y[idx].squeeze(), cmap='gray')\n","\n","plt.subplot(1,3,2)\n","plt.title(\"Predicted\")\n","plt.imshow(predicted_image[0].squeeze(), cmap='gray')\n","\n","plt.subplot(1,3,3)\n","error_map = np.abs(y[idx].squeeze() - predicted_image[0].squeeze())\n","mse = np.mean((y[idx] - predicted_image[0])**2)\n","error_percent = mse * 100\n","plt.title(f\"Error Map\\nMSE: {mse:.5f}, Error: {error_percent:.2f}%\")\n","plt.imshow(error_map, cmap='hot')\n","plt.colorbar()\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"PcaLRNKf4QyA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # === Autoregressive N-step 예측 ===\n","\n","# # 초기 latent 시퀀스 선택 (정규화된 값 사용)\n","# input_seq = latent_seqs_scaled[idx:idx+1].copy()  # (1, 12, latent_dim)\n","\n","# n_future = 5  # 예측할 미래 이미지 수\n","# generated_latents_scaled = []\n","\n","# for _ in range(n_future):\n","#     # GRU 예측 (정규화된 latent vector)\n","#     pred_scaled = predictor.predict(input_seq)\n","\n","#     # 저장\n","#     generated_latents_scaled.append(pred_scaled[0])\n","\n","#     # 다음 입력 시퀀스로 갱신\n","#     input_seq = np.concatenate([input_seq[:,1:,:], pred_scaled[:,np.newaxis,:]], axis=1)\n","\n","# # 역정규화\n","# generated_latents = scaler.inverse_transform(np.array(generated_latents_scaled))  # (n_future, latent_dim)\n","\n","# # 이미지 복원\n","# generated_images = decoder.predict(generated_latents)\n","\n","# # 시각화\n","# import matplotlib.pyplot as plt\n","\n","# plt.figure(figsize=(15,3))\n","# for i in range(n_future):\n","#     plt.subplot(1, n_future, i+1)\n","#     plt.imshow(generated_images[i].squeeze(), cmap='gray')\n","#     plt.title(f\"T+{i+1}\")\n","#     plt.axis('off')\n","# plt.tight_layout()\n","# plt.show()\n"],"metadata":{"id":"Q8jddc1p8VxH"},"execution_count":null,"outputs":[]}]}